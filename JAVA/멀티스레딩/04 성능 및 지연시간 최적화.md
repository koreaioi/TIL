# 성능

1. 지연 시간 (Latency)
2. 처리량 (Throughput)

보통 고속 트레이딩 시스템 (Buy, Sell)에서는 성능의 기준을 지연시간으로 측정한다.      
즉, 트랜잭션이 빠를수록 어플리케이션의 성능이 더 중요하다.   
또는 하나의 큰 파일을 여러 조각으로 나누어 병렬 다운로드   
와 같은 방법이 있다.


지연시간 말고도 처리량도 성능을 측정하는 요소 중 하나이다.   


# Latency

싱글 스레드로 순차적으로 완료할 수 있는 작업의 지연시간을 T라고 할 때,   
해당 작업을 N개의 작업으로 나누고 멀티 스레딩하면?   
지연시간은 T/N이 된다.   

하지만 이는 이상적인 수치일 뿐, 실제로도 그럴까??   

너무나 당연하게도 멀티스레드는 지연 시간 성능을 줄인다. (N의 증가)   
하지만, 이때 하위 작업들이 각각 다른 코어에서 실행되어야 완전한 병렬 실행의 이점을 가져갈 수 있다.   
또한 각각의 작업들을 같은 작업 시간이 되도록 나눈 다음 동시에 시작해서 동시에 나눠야지 멀티 스레드의 이상적인 결과를 얻을 수 있다. 실제로 그럴까?
- 할당된 모든 스레드가 가능한 Runnable 상태를 유지 -> 모든 작업이 병렬로 동시에 동작 후 쉬지않고 작업을 동시에 마친다. -> 너무 이상적   
- 작업이 동작하는 중 인터럽트가 발생하지 않아야 한다. -> IO나 블로킹 호출이 스레드 처리 과정 중 없어야함 -> 현실적으로 불가능
- 이론상 병렬 처리는 무조건 좋지만, 현실적인 여러 여건으로 작업의 크기가 너무 크지 않다면 싱글 스레드로 처리하는 게 더 성능 상 좋다.   


## 하이퍼 스레딩을 사용한다면?

하이퍼 스레딩은 코어 하나가 스레드 두 개를 동시에 실행할 수 있다는 뜻이다.   
말 뜻대로 실제로 하나의 코어에 스레드가 100% 병렬로 실행될까?   

하이퍼 스레딩은 물리적인 코어의 하드웨어 유닛 일부를 공유한다.   
이말은 일부 유닛은 복제하고, 다른 유닛은 공유한다는 뜻이다.   
- 레지스터 파일, 명령어 큐와 같은 복제된 자원은 스레드간 독립적으로 사용할 수 있다.   
- 캐시 메모리, 산술 논리 연산 장치와 같은 공유되는 자원은 어쩔 수 없이 스레드간 공유하여 사용한다.
- 즉, 두 스레드를 동시에 실행하기 위해 고안된 하이퍼 스레딩도 공유되는 자원을 사용하는 순간 경쟁이 발생하여 한 스레드는 결국 대기를 해야한다.   
- 따라서 하이퍼 스레딩의 실제 성능 향상은 20~30%라고 한다. (하나의 코어에서 두 스레드를 100% 병렬처리 할 수 없음)


## 멀티 스레드 구현 비용
멀티 스레드를 구현 하기 위해서 드는 비용은 다음과 같다.

- 큰 작업을 작은 작업들로 나누는 과정 (비용)
- 스레드를 생성, 작업을 전달하고 작업을 시작하는 과정 (비용)
- 운영체제가 스레드를 스케줄링 하는 과정 (비용)
- 마지막 스레드가 완료되고 모든 작업 결과물을 얻는 신호를 기다리면서 발생하는 대기 비용
- 결과를 합치는 스레드가 신호를 받아 실행될때 까지의 비용
- 모든 결과물을 하나로 합치는 비용

따라서 보통 큰 작업이 아닌 이상 싱글 스레드 처리가 유리하다.   

## 작업을 어떻게 분류할까?
1. 병행 가능하고 쉽게 분할되는 작업 (작업 순서를 상관 X)
2. 분할이 불가능하여 무조건 싱글 스레드를 쓸 수 밖에 없는 작업
3. 분할은 가능하지만 순차적으로 실행해야 하는 작업 (작업 순서 상관 O)


<hr>

# 처리량 (Throughput)

지연 시간을 줄이기 위해서 하나의 작업을 여러 작업으로 나누는 방식을 알아봤다.   
이는 한 작업의 처리 시간을 줄이기 위한 해결 방법일 뿐, 단위 시간 당 얼마나 많은 처리를 할 수 있는가 즉, 처리량을 성능으로 삼을 때 여러 작업으로 나누는 방식은 적절치 않다.   
- 태스크를 서브 태스크로 나누는것은 추가 오버헤드를 발생시켜 단위 시간당 처리할 수 있는 처리량이 줄어들 수 있다.   

따라서 처리량을 늘리기 위해서는 서로 상관없는 별개의 작업을 별도의 스레드로 병렬 실행한다.   
이렇게 하면 작업을 나누지 않아 멀티 스레드 구현 비용이 발생하지 않는다. 따라서 별개의 작업이므로 다른 스레드의 작업을 기다리지 않아도 된다.


### 참고
- 물리적 코어 4개를 가진 시스템에서 하이퍼스레딩으로 8개의 스레드를 실행하면, 코어 자원의 활용도가 극대화되어 이론적으로 가능한 최대 처리량에 도달할 수 있다.   
- 중요한 전제는 작업을 나누고 합치는 오버헤드가 없고, 스레드 간의 경합 없이 병렬 처리가 완벽히 이루어진다는 것입니다.   
- 현실에서는 동기화 비용, 메모리 병목, I/O 대기 등으로 인해 항상 이렇게 이상적인 결과를 얻기는 어렵습니다.

# 스레드 풀링

스레드를 생성하고 미래 작업을 위해 다시 스레드를 사용한다. (새 스레드를 생성하지 않고 스레드를 재사용.)      
스레드가 생성되면 풀에 쌓이고 작업은 대기열을 통해 스레드 별로 분배된다.   
모든 스레드가 Runnable한 상태를 최대한 유지하게 해서 모든 스레드가 작업 중이면, 작업은 대기 큐에서 기다린다.   


# 코어 수 ~ 스레드 수

### CPU 집약적 작업 (예: 과학 계산, 3D 렌더링)
- CPU가 항상 바쁘게 계산을 수행하는 작업.   
- CPU가 대부분의 시간을 사용하여 계산을 수행하는 작업.   
- 코어와 스레드 수가 1:1이 적합. (한 스레드만 사용해 CPU 자원을 완전히 활용)
- 하이퍼스레딩을 사용하면 자원 공유로 인해 오히려 성능 저하 가능.   
  - CPU의 모든 코어가 100%로 활성화 상태 -> 추가 스레드가 더해도 오히려 오버헤드만 발생
### I/O 집약적 작업 (예: 네트워크, 디스크 읽기/쓰기)
- 작업이 CPU보다 디스크, 네트워크 I/O에서 병목 현상이 발생하는 경우.
- CPU는 주로 데이터를 기다리면서 쉬고, 작업의 대부분이 I/O 장치와의 데이터 전송에 소요.   
- 1:2 이상의 비율이 효과적.
- I/O 작업 중 CPU는 유휴 상태일 가능성이 높다(아무것도 안하고 쉬는 상태), 더 많은 스레드로 병렬 처리가 가능.
- 유휴 상태일때는 다른 작업을 처리할 수 없음 따라서 여러 스레드로 나눠서, 하나의 스레드가 I/O 작업으로 대기중 일때, 다른 스레드는 CPU에서 작업을 수행하도록한다.

<details>
<summary>유휴 상태</summary>

- 스레드를 늘리면 유휴 시간이 줄어드는 이유
    -  (1) 스레드가 하나인 경우 
     작업 1개를 처리하고 있을 때, I/O 작업 중 CPU는 기다리고만 있습니다(I/O 대기 상태이자 유휴 상태).
     이때, CPU가 쉬고 있는 동안 다른 작업을 처리할 수 없습니다.
    - (2) 스레드가 여러 개인 경우   
    여러 스레드가 동시에 실행되도록 하면:
    하나의 스레드가 I/O 작업으로 대기 중일 때, 다른 스레드가 CPU에서 작업을 수행할 수 있습니다.
    결과적으로 **CPU가 쉬는 시간(유휴 시간)**이 줄어들게 됩니다.


</details>

### 멀티태스킹 작업 (예: 웹 서버, 다중 사용자 처리)
- 많은 사용자의 요청을 동시에 처리해야 하는 작업.
- 1:2 ~ 1:4 비율이 적합.
- 많은 스레드가 효율적이지만, 스레드 컨텍스트 스위칭 오버헤드를 고려해야 함.



